{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sspa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import gseapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed proteomics data\n",
    "prot = pd.read_csv('/Users/judepops/Documents/PathIntegrate/Code/Processing/Processing_Cleaned/cleaned_metabolomics_data_covid.csv')\n",
    "\n",
    "# processed metaboloimcs data\n",
    "metab = pd.read_csv('/Users/judepops/Documents/PathIntegrate/Code/Processing/Processing_Cleaned/cleaned_proteomics_data_covid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Metabolomics Identifer Harmonisation with Metaboanalyst for ssPA and PathIntegrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_names = metab.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_names = processed_data.columns.tolist()\n",
    "conversion_table = sspa.identifier_conversion(input_type=\"name\", compound_list=compound_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_table['ChEBI'] = pd.to_numeric(conversion_table['ChEBI'], errors='coerce')\n",
    "\n",
    "conversion_table.dropna(subset=['ChEBI'], inplace=True)\n",
    "conversion_table['ChEBI'] = conversion_table['ChEBI'].astype('Int64')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using mapping table to convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_mapped = sspa.map_identifiers(conversion_table, output_id_type=\"ChEBI\", matrix=processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Pathway Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will import the metabolite pathways from the Reactome database\n",
    "# We must specify one of the Reactome organism names\n",
    "# This returns a GMT format pandas DataFrame containing the pathway information\n",
    "reactome_pathways  = sspa.process_reactome(organism=\"Homo sapiens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking IDs mapping to pathway databsase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if using Reactome database as the pathway database\n",
    "# count all compounds in the dataset\n",
    "print(len(compound_names), \"compounds in the dataset\")\n",
    "\n",
    "# find how many input compound names in the dataset had a matching ChEBI ID\n",
    "chebi_matches = conversion_table[(conversion_table[\"Comment\"] == \"1\") & (conversion_table[\"ChEBI\"].isnull()==False)][\"ChEBI\"]\n",
    "print(len(chebi_matches), \"compounds from the dataset that have ChEBI IDs\")\n",
    "\n",
    "# count all unique compounds in the Reactome database\n",
    "all_reactome_cpds = set(sum(sspa.utils.pathwaydf_to_dict(reactome_pathways).values(), []))\n",
    "print(len(all_reactome_cpds), \"total unique compounds in Reactome\")\n",
    "\n",
    "# find the intesect between all reactome compounds and all ChEBI IDs annotated to the dataset\n",
    "mapped_annotated_cpds = set(processed_data_mapped.columns) & all_reactome_cpds\n",
    "print(len(mapped_annotated_cpds), \"compounds present in both the dataset and Reactome pathways\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('notebook')\n",
    "sns.set_style('ticks')\n",
    "sns.barplot(y=[len(compound_names), len(chebi_matches), len(mapped_annotated_cpds)], x=['Original', 'Mapping to CHEBI', 'Annotated to Reactome'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"\n",
    "\n",
    "df = pd.DataFrame(compound_names, columns=['Original_ID'])\n",
    "df[\"Matched_ID\"] = df['Original_ID'].map(dict(zip(conversion_table[\"Query\"], conversion_table[\"ChEBI\"])))\n",
    "df[\"In_pathway\"] = [i if i in mapped_annotated_cpds else \"NA\" for i in df[\"Matched_ID\"] ]\n",
    "df = df.replace({\"NA\":0})\n",
    "df[df != 0] = 1\n",
    "df = df.astype(\"float\")\n",
    "df.index = compound_names\n",
    "\n",
    "fig = px.bar(df)\n",
    "fig.show(renderer=\"colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the MetaboAnalyst Mapped Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab.to_csv('/Users/judepops/Documents/PathIntegrate/Code/Pathway_Analysis/COVID_Met_ChEBI_Final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Performing single-sample pathway analysis (ssPA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the SVD scores method that will be used throughout this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpca_scores = sspa.sspa_SVD(reactome_pathways, min_entity=3, random_state=1).fit_transform(processed_data_mapped)\n",
    "\n",
    "# Inspect the pathway score matrix\n",
    "kpca_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pathway-based PCA plot\n",
    "\n",
    "# Normalise kPCA scores\n",
    "kpca_scores_norm = pd.DataFrame(StandardScaler().fit_transform(kpca_scores))\n",
    "\n",
    "# Perform two component PCA using sklearn\n",
    "pca = PCA(n_components=2)\n",
    "pca_res = pca.fit_transform(kpca_scores_norm)\n",
    "\n",
    "# determine the variance explained by the first 2 components\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "# Plot the first two components as a scatterplot\n",
    "plt.style.use(\"default\")\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "sns.scatterplot(x=pca_res[:, 0 ], y=pca_res[:, 1], hue=covid_data[\"Group\"], ax=ax1, s=50, alpha=0.5)\n",
    "sns.scatterplot(x=pca_res[:, 0 ], y=pca_res[:, 1], hue=covid_data[\"WHO_status\"], ax=ax2, s=50, alpha=0.5)\n",
    "\n",
    "# Set axis labels\n",
    "ax1.set_xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)')\n",
    "ax1.set_ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)')\n",
    "ax2.set_xlabel('PC1 (' + str(round(pca.explained_variance_ratio_[0]*100,2)) + '%)')\n",
    "ax2.set_ylabel('PC2 (' + str(round(pca.explained_variance_ratio_[1]*100,2)) + '%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\".kpca_pca_plots.png\", dpi=350, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the loadings of the pathway-based PCA\n",
    "loadings = pd.DataFrame(pca.components_.T* np.sqrt(pca.explained_variance_)*10,columns=['PC1','PC2'], index=kpca_scores.columns)\n",
    "\n",
    "# add pathway names to the loadings dataframe\n",
    "loadings['Pathway'] = loadings.index.map(dict(zip(reactome_pathways.index, reactome_pathways['Pathway_name'])))\n",
    "\n",
    "# subset top 10 loadings for visual clarity\n",
    "loadings_top_10 = loadings.sort_values(by='PC1').iloc[0:10, :]\n",
    "\n",
    "# Plot the first two components as a scatterplot\n",
    "fig = px.scatter(x=pca_res[:, 0 ], y=pca_res[:, 1], color=covid_data[\"Group\"], labels={'x':'PC1', 'y':'PC2'})\n",
    "\n",
    "# Plot lines to origin representing the loadings\n",
    "for i in range(0, loadings_top_10.shape[0]):\n",
    "  fig.add_trace(go.Scatter(x=[0, loadings_top_10.iloc[i, :]['PC1']], y=[0, loadings_top_10.iloc[i, :]['PC2']],\n",
    "                           line_color='black', marker_size=0, text=loadings_top_10.iloc[i, :]['Pathway']))\n",
    "\n",
    "fig.update_layout(width=600, height=600, yaxis_range=[-10, 10], xaxis_range=[-15, 15], showlegend=False)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a heatmap using the pathway scores\n",
    "g = sns.clustermap(kpca_scores_norm.T,\n",
    "               cmap=\"RdBu_r\",\n",
    "               z_score=1,\n",
    "              col_colors = [\"tab:red\" if i == \"COVID19 \" else \"tab:green\" for i in covid_data[\"Group\"]],\n",
    "              xticklabels=False,\n",
    "              yticklabels=False)\n",
    "g.ax_heatmap.set_xlabel(\"Samples\")\n",
    "g.ax_heatmap.set_ylabel(\"Pathways\")\n",
    "\n",
    "# plt.savefig(\"kpca_heatmap.png\", dpi=350, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Using PathIntegrate for Machine Learning on the ssPA scores matrix calculated by ssPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathintegrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the identifier-mapped datasets back in (before ssPA has been run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metab = pd.read_csv('/Users/judepops/Documents/PathIntegrate/Code/Pathway_Analysis/COVID_Met_ChEBI_Final.csv')\n",
    "prot = pd.read_csv('/Users/judepops/Documents/PathIntegrate/Code/Pathway_Analysis/COVID_Pro_UniProt_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping irrelevant metadata columns\n",
    "prot = prot.drop(columns=['Who', 'Race', 'Age', 'Group', 'Age_Group', 'Race_Group'])\n",
    "metab = metab.drop(columns=['Who', 'Race', 'Age', 'Group', 'Age_Group', 'Race_Group'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure only matching samples are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot.set_index('sample_id', inplace=True)\n",
    "metab.set_index('sample_id', inplace=True)\n",
    "metab['Condition_Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices = prot.index.intersection(metab.index)\n",
    "prot = prot.loc[common_indices]\n",
    "metab = metab.loc[common_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Reactome Pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mo_paths = sspa.process_reactome(\n",
    "    organism='Homo sapiens',\n",
    "    download_latest=True,\n",
    "    omics_type='multiomics',\n",
    "    filepath='.' # save to current directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inititating PathIntegrate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVD and min 4 compound per pathway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_model = pathintegrate.PathIntegrate(\n",
    "    omics_data={'Metabolomics': metab.iloc[:, :-1], 'Proteomics':prot.iloc[:, :-1]}, # dictionary of multi-omics DataFrames and names for each omics\n",
    "    metadata=prot['Condition_Group'], # metadata column\n",
    "    pathway_source=mo_paths, # pathways dataframe\n",
    "    sspa_scoring=sspa.sspa_SVD, # ssPA method, see ssPA package for options\n",
    "    min_coverage=4) # minimum number of molecules mapping per pathway to be included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a cross-validated single-vew PathIntegrate model for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection a train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making sure the labels are binary and unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, y = np.unique(prot['Condition_Group'], return_inverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split for each multi-omics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prot, X_test_prot, y_train, y_test = train_test_split(prot, y, test_size=0.33, random_state=0, stratify=y)\n",
    "# use the indices from the protein data to subset the metabolite data\n",
    "X_train_met, X_test_met = metab.loc[X_train_prot.index, :], metab.loc[X_test_prot.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a model with the training data only\n",
    "pi_model = pathintegrate.PathIntegrate(\n",
    "    omics_data={'Metabolomics_train': X_train_met, 'Proteomics_train': X_train_prot.iloc[:, :-1]},\n",
    "    metadata=y_train,\n",
    "    pathway_source=mo_paths,\n",
    "    sspa_scoring=sspa.sspa_SVD,\n",
    "    min_coverage=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting cross-validated performance metrics from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "cv_single_view = pi_model.SingleViewCV(\n",
    "    LogisticRegression,\n",
    "    model_params={'random_state':0, 'max_iter':500},\n",
    "    cv_params={'cv':5, 'scoring':'f1', 'verbose':2})\n",
    "\n",
    "print('Mean cross-validated F1 score: ', np.mean(cv_single_view))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing grid search cross valridation to get hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    \"model__C\": np.logspace(-4, 4, 4), # every parameter must begin with \"model__\"\n",
    "}\n",
    "\n",
    "sv_grid_search = pi_model.SingleViewGridSearchCV(\n",
    "    model=LogisticRegression,\n",
    "    param_grid=param_grid,\n",
    "    grid_search_params={'cv':3, 'scoring':'roc_auc', 'verbose':2}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = sv_grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_grid_search.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fittign optimised model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_grid_search.best_params_\n",
    "sv_tuned = pi_model.SingleView(\n",
    "    model=LogisticRegression,\n",
    "    model_params={'C': best_params['model__C'], 'random_state': 0, 'max_iter': 500}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualising sspa scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_tuned.sspa_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predicting on unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate multi-omics pathway scores for test set\n",
    "concat_data = pd.concat({'Metabolomics_test': X_test_met, 'Proteomics_test': X_test_prot.iloc[:, :-1]}.values(), axis=1)\n",
    "\n",
    "pipe_sv = Pipeline([\n",
    "            ('Scaler', StandardScaler().set_output(transform=\"pandas\")),\n",
    "            ('sspa', pi_model.sspa_method(pi_model.pathway_source, pi_model.min_coverage)),\n",
    "        ])\n",
    "\n",
    "test_set_scores = pipe_sv.fit_transform(concat_data)\n",
    "\n",
    "# predict using the test set scores\n",
    "sv_pred = sv_tuned.predict(test_set_scores)\n",
    "\n",
    "# evalaute the prediction\n",
    "test_set_f1 = f1_score(y_test, sv_pred)\n",
    "print(test_set_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# display confusion matrix for test set\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(\n",
    "    data=confusion_matrix(y_test, sv_pred),\n",
    "    annot=True,\n",
    "    square=True,\n",
    "    cmap='Blues',\n",
    "    )\n",
    "\n",
    "# set x and y labels\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curve for test set\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "fpr, tpr, _ = roc_curve(y_test, sv_tuned.predict_proba(test_set_scores)[:, 1])\n",
    "plt.plot(fpr, tpr, label='Test set')\n",
    "\n",
    "# plot ROC curve for training set\n",
    "fpr, tpr, _ = roc_curve(y_train, sv_tuned.predict_proba(sv_tuned.sspa_scores)[:, 1])\n",
    "plt.plot(fpr, tpr, label='Training set')\n",
    "\n",
    "# add roc score to plot\n",
    "plt.plot([0,1], [0, 1], linestyle='--', label='Random', c='k')\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "\n",
    "# add legend\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
